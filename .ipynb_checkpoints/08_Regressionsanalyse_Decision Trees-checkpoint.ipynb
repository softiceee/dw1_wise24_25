{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee4a8a80-bc20-4fdb-985e-061d41fa23a1",
   "metadata": {},
   "source": [
    "# Regressionsanalyse\n",
    "\n",
    "In dieser Übung werden wir die in der Vorlesung kennengelernten Inhalte zur Regressionsanalyse direkt in R anwenden. Dafür werden wir uns zunächst eine einfache lineare Regression ansehen. Diese können wir mit Tools von `base` oder auch direkt in einer Grafik mit `ggplot2` umsetzen. \n",
    "\n",
    "Anschließend wollen wir die Decision Trees aus der vorhergehenden Übung mit der Regressionsanalyse verbinden. Wir werden uns ein Modell bauen, welches analog wie die klassifizierenden Decision Trees funktioniert, aber mit kontinuierlichen Variablen arbeiten kann! Wir erinnern uns – in der letzten Wochen hatten wir es mit Klassifizierungsproblemen zu tun. D.h., eine Zielvariable konnte nur eine begrenzte Anzahl an Kategorien annehmen (die Pilze konnten z.B. nur `edible` oder `poisonous` sein). Jetzt lernen wir ein Modell kennen, welches für numerische, kontinuierliche Variablen funktioniert.\n",
    "\n",
    "Für die theoretischen Grundlagen der Regressionsanalyse sei an dieser Stelle wieder auf die Vorlesung verwiesen.\n",
    "\n",
    "Um die Performance unseres Modells zu verbessern, werden wir am Ende statt der einfach Decision Trees mit `rpart` einen Random Forest-Algorithmus verwenden. Dazu später mehr."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "814f2ea4-dd9f-4bd3-a45b-478a4c644993",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zunächst laden wir wieder die Pakete aus der letzten Session sowie palmerpenguins für die lineare Regression mit ggplot2\n",
    "pacman::p_load(\n",
    "    tidyverse,\n",
    "    tidymodels,\n",
    "    vip,\n",
    "    rpart.plot,\n",
    "    palmerpenguins\n",
    "    )\n",
    "\n",
    "set.seed(123) # for reproducibility\n",
    "\n",
    "# Set the default plot width for Jupyter Notebook display\n",
    "options(repr.plot.width = 12, repr.plot.height = 8, digits = 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eeea7fe-f191-4f3a-87a0-3334356e6ab7",
   "metadata": {},
   "source": [
    "## Lineare Regression\n",
    "\n",
    "Zunächst wollen wir eine einfache lineare Regression durchführen. Dafür können wir wieder den Datensatz der Antarktis-Pinguine `palmerpenguins` benutzen. Über die Pinguine des Datensatzes wurden verschiedene Parameter erhoben, wie beispielsweise die Flügellänge `flipper_length_mm` und das Körpergewicht `body_mass_g`. \n",
    "\n",
    "Aus der Biologie ließe sich an dieser Stelle eventuell ein erster Zusammenhang zwischen Flüggellänge und Körpergewicht vermuten. Durch eine größere Flügellänge könnte man vielleicht auf einen größeren Körperbau und damit auch auf einen größeres Körpergewicht schließen. Das ist eine gute Fragestellung für eine Regressionsanalyse. \n",
    "\n",
    "Wir vermuten erstmal einen linearen Zusammenhang zwischen Flüggellänge und Körpergewicht. Wie wir in der letzten Sitzung bereits kennengelernt haben, werden Datenanalyse-Modelle in R in der Regel durch eine Formel definiert, die eine Tilde `~` enthält. Die Tilde heißt soviel wie \"wird vorhergesagt durch\". Der Zusammenhang, den wir jetzt untersuchen, können wir also mit `flipper_length_mm ~ body_mass_g` definieren – wir vermuten, dass das Körpergewicht linear von der Flügellänge abhängt. \n",
    "\n",
    "In `base` können wir lineare Modell mithilfe der Funktion `lm()` (für *linear model*) fitten. Wir übergeben `lm()` als erstes Argument unsere Formel `body_mass_g ~ flipper_length_mm` und an zweiter Stelle den Datensatz `penguins`. Anschließend lassen wir uns die Ergebnisse des Modells mithilfe von `summary()` ausgeben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e2c448-2e9e-484b-b477-0acae96cd96a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm(body_mass_g ~ flipper_length_mm, data = penguins) %>% \n",
    "    summary() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1639652d-77e5-4c0a-8162-145b19bf786b",
   "metadata": {},
   "source": [
    "Hui, da kommen erstmal viele Informationen auf einmal! Für uns sind zunächst einmal zwei Teile des Outputs interessant:\n",
    "\n",
    "* Unter **Coefficients** können wir uns die Koeffizienten unseres Regressionsmodells ausgeben lassen. Unser Modell folgt der Formel $ \\hat{y}_i = b_0 + b_1 * x_i $, wobei $\\hat{y}$ die Vorhersage unserer Zielgröße `body_mass_g` und $x$ unsere Prädiktorvariable `flipper_length_mm` ist. Die anderen Parameter der Regressionsgleichung $b_0$ und $b_1$ unseres Modells werden in der Zusammenfassung unter Coefficients -> Estimate ausgegeben. Der Intercept ist $b_0$ (= vorhergesagter Wert für x = 0). Die Steigung der Regressionsgerade, also $b_1$ finden wird auch unter Estimates, in der Zeile neben der unabhängigen Variable `flipper_length_mm`. In dieser Form ist das ganze für uns natürlich eher schwierig interpretierbar, daher werden wir gleich kennenlernen, wie wir das lineare Modell visualisieren können.\n",
    "\n",
    "* Die zweite für uns interessante Variable ist **(Multiple) R-squared**. $R^2$, oder auch R-squared, drückt aus, wie viel der Varianz in der abhängigen Variable (hier `body_mass_g`) statistisch gesehen durch die Varianz in der unabhängigen erklärt wird (hier also `flipper_length_mm`). Mithilfe von R-squared können wir die Güte des Regressionsmodells bewerten. `0.759` ist zunächst mal ein eher höheres R-squared, sodass wir von einem gewissen Zusammenhang zwischen `body_mass_g` und `flipper_length_mm` ausgehen können!\n",
    "\n",
    "### In `tidymodels`\n",
    "\n",
    "<img src=\"https://broom.tidymodels.org/logo.png\" alt=\"rsample\" width=\"100\" align=\"right\" /> In `tidymodels` können wir diese Werte auch anders extrahieren, und zwar mit `tidy()` und `glance()`. Daher werden wir ab dieser Stelle mit dem `tidymodels`-Ansatz weitermachen. `tidy()` und `glance()` funktionieren ziemlich analog zu `summary()`, geben die Ergebnisse aber in einem tidy-Format, also als `tibble` aus. Sie gehören beide zum Paket `broom`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e3958f-519e-4427-8721-157e4439d764",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm(body_mass_g ~ flipper_length_mm, data = penguins) %>% \n",
    "    tidy()\n",
    "\n",
    "lm(body_mass_g ~ flipper_length_mm, data = penguins) %>% \n",
    "    glance()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "737705d7-996e-45b9-a09f-b9a91d6e80b6",
   "metadata": {},
   "source": [
    "Auch hier interessieren uns erstmal nur die Maße `estimate` (die Schätzwerte für den linearen Zusammenhang `body_mass_g ~ flipper_length_mm`, `std.error` (die Standardabweichung) und das `r.squared` ($R^2$)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c995566-63ce-440a-897c-59408cb4f20b",
   "metadata": {},
   "source": [
    "### Visualisierung\n",
    "\n",
    "Der Übersichtlichkeit halber wollen wir das lineare Modell jetzt einmal visualisieren. Dazu kombinieren zwir zwei Geome. Zunächst visualisieren wir den Zusammenhang zwischen $x$ & $y$ mit einem Scatterplot und `geom_point()`. Wir plotten `flipper_length_mm` auf der x-Achse und `body_mass_g` auf der y-Achse. Für die Regressionsgerade hat `ggplot2` praktischerweise ein eigenes **geom** eingebaut, und zwar `geom_smooth()`. Diesem Geom geben wir unsere Formel mit `y ~ x` (die Variablen haben wir im Mapping gewissermaßen \"umgetauft\"). \n",
    "Der Code dafür sieht dann folgendermaßen aus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bde0842-2aef-405f-b7b4-f97dbf4a77e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "penguins %>%\n",
    "    drop_na() %>% # remove NA values to avoid warnings\n",
    "    ggplot(mapping = aes(x = flipper_length_mm, y = body_mass_g)) +\n",
    "    geom_point(size = 2) +\n",
    "    geom_smooth(method = \"lm\", formula = y ~ x) +\n",
    "    theme_minimal(base_size = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5ecbe26-f7ab-40ee-9ea1-610d887fcb3d",
   "metadata": {},
   "source": [
    "Wir können hier unseren vermuteten linearen Zusammenhang ganz gut erkennen, oder? Mit steigender Flüggellänge wird auch das Körpergewicht tendenziell schwerer. In der Realität muss man allerdings aufpassen, wo man welche Zusammenhänge vermuten kann. Wir haben in unserem Datensatz ja 3 verschiedene Spezies abgebildet, und es ist nicht automatisch gegeben, dass der Zusammenhang für alle diese Spezies gleich ist. Daher ist es sinnvoll, nochmal ein lineares Modell zu visualisieren, welches eine Regression getrennt je nach Spezies erstellt. Das funktioniert mit `ggplot2` ziemlich einfach, dafür müssen wir einfach `aes()` ein zusätzliches Argument übergeben.\n",
    "\n",
    "1. Was für eine Grafik erwartet ihr, wenn die Regression für jede einzelne Spezies ausgeführt wird?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f97633-4362-4a61-a9f7-eab10759f3ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "penguins %>%\n",
    "    drop_na() %>% # remove NA values\n",
    "    ggplot(mapping = aes(x = flipper_length_mm, y = body_mass_g, color = species)) +\n",
    "    geom_point(size = 2) +\n",
    "    geom_smooth(method = \"lm\", formula = y ~ x) +\n",
    "    theme_minimal(base_size = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62343332-0f70-4a06-b77d-c1659f16aba1",
   "metadata": {},
   "source": [
    "Voilà, wir bekommen jetzt einen Plot ausgegeben, bei dem wir pro Spezies ein eigenes lineares Modell abgebildet bekommen. Wenn wir uns wie weiter oben auch die genauen Koeffizienten und R-squared ausgeben lassen wollen, können wir das folgendermaßen machen.\n",
    "\n",
    "2. Bevor ihr den Code ausführt, überlegt euch, was jede Zeile macht. Schlagt dafür gerne den Befehl `do()` einmal kurz nach!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87176564-3796-4c13-a80f-2f3b92633253",
   "metadata": {},
   "outputs": [],
   "source": [
    "penguins %>%\n",
    "    drop_na() %>%\n",
    "    group_by(species) %>%\n",
    "    do(tidy(lm(body_mass_g ~ flipper_length_mm, data = .)))\n",
    "\n",
    "penguins %>%\n",
    "    drop_na() %>%\n",
    "    group_by(species) %>%\n",
    "    do(glance(lm(body_mass_g ~ flipper_length_mm, data = .))) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a64f43e-498b-4314-9ddb-df5b54b20abd",
   "metadata": {},
   "source": [
    "3. Wie würdet ihr die Werte für `r.squared` interpretieren?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff9641f3-8547-49f8-ac3d-45abf29bb21a",
   "metadata": {},
   "source": [
    "Natürlich können wir auch andere Zusammenhänge abbilden. Wir könnten als Formel auch `flipper_length_mm ~ body_mass_g` angeben, wenn wir ein umgekehretes Abhängigkeitsverhältnis vermuten würden. Man könnte über `+` auch noch weitere Vorhersagevariablen in das Modell einbeziehen. Wie genau man ein Regressionsmodell spezifiziert ist vor allem eine Frage von theoretischen oder sachlogischen Überlegungen. Weitere Informationen zu den Möglichkeiten zur Umsetzung in R findet ihr wie gewohnt in der Dokumentation von `lm()`.\n",
    "\n",
    "Wir werden in dieser Übung zunächst nicht weiter auf `lm()` eingehen, sondern möchten jetzt die Decision Trees von letzter Woche mit der Regressionsanalyse verbinden."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60936c99-6dcd-4e07-8413-b12928a3bbc5",
   "metadata": {},
   "source": [
    "# Regression mit Decision Trees\n",
    "\n",
    "Eine Regression mit Decision Trees funktioniert ähnlich wie eine Klassifikation, zielt aber darauf ab, statt diskreten Kategorien kontinuierliche Werte zu prognostizieren. \n",
    "\n",
    "Wir möchten wieder die Beziehung zwischen Prädiktor- und Zielvariable ermitteln. Der Decision Tree teilt den Datensatz entlang der Prädiktorvariablen in immer homogenere Teilgruppen auf, um möglichst genau die Beziehung zur Zielvariable zu bestimmen. Nachdem das Modell trainiert wurde, können wir es wieder zur Vorhersage neuer Datenpunkte verwenden! Decision Trees für die Regressionsanalyse haben den Vorteil, auch nichtlineare Beziehungen zwischen Prädiktoren und Zielvariable abbilden zu können, anders als eine einfache lineare Regression."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5580aab6-360a-4a5e-b8b6-3b0bfb88c443",
   "metadata": {},
   "source": [
    "Als erstes Beispiel schauen wir uns einen [Datensatz](https://archive.ics.uci.edu/dataset/275/bike+sharing+dataset) von Hadi Fanaee-T aus dem [UCI Machine Learning Repository](http://archive.ics.uci.edu/) zum Thema Bike Sharing an.\n",
    "\n",
    "> This dataset contains the hourly and daily count of rental bikes between years 2011 and 2012 in Capital bikeshare system with the corresponding weather and seasonal information.\n",
    "\n",
    "## Daten explorieren und vorbereiten\n",
    "\n",
    "Der Datensatz im [UCI Machine Learning Repository](http://archive.ics.uci.edu/) ist bereits soweit vorbereitet, dass alle kategorialen Variablen in numerische Variablen umkodiert wurden. Der Vollständigkeit halber gehen wir damit aber einen Schritt zurück, und tun erstmal so, als wäre das noch nicht passiert.\n",
    "\n",
    "Der Datensatz liegt im Ordner `data/regression/bike_sharing.csv`. \n",
    "\n",
    "4. Ladet den Datensatz mit `read_csv()` und schaut ihn euch an. Was könnte unsere Zielvariable sein, welche Variablen die relevanten Prädiktoren? Falls die Variablenbezeichnungen uneindeutig sind, schaut im UCI Machine Learning Repository nach, welche Bedeutung sie haben?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "075ba2fe-ed54-4099-81c0-a94bf0250cad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2f671a2a-754c-49bf-9995-37c1524d5dda",
   "metadata": {},
   "source": [
    "Um den Datensatz besser zu explorieren, könntet ihr wieder eine visuelle Analyse vornehmen, bspw. mit `facet_wrap()`. Erinnert ihr euch dafür ans letzte Notebook.\n",
    "\n",
    "5. Exploriert 1-2 Variablen mithilfe von `ggplot2`. Ihr könnt alternativ auch `facet_wrap()` benutzen, um bspw. alle numerischen Variablen zu visualisieren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "545f6c63-4420-4da7-9a71-d5169c4e086d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "777b9c9e-f59a-45e5-945d-1c8fd23ccb73",
   "metadata": {},
   "source": [
    "### Supervised Learning\n",
    "\n",
    "<img src=\"https://rsample.tidymodels.org/logo.png\" alt=\"rsample\" width=\"100\" align=\"right\" /> In einem letzten Schritt der Vorbereitung teilen wir wie letzte Woche unseren Datensatz wieder in Trainings- und Testdaten auf. \n",
    "\n",
    "Sinnvollerweise müssen wir vor der Modellierung einige Variablen aus dem Datensatz entfernen. Die Variable `instant` ist lediglich ein Index, wir können sie also rausschmeißen. Die Variable `dteday` ist vom Typ `date` und daher können wir diese nicht in der Regressionsanalyse berücksichtigen. Abgesehen davon ist das Datum ja ebenfalls in den Variablen `yr` und `mnth` berücksichtigt.\n",
    "\n",
    "Für eine Organisation, die Bike Sharing betreibt, ist vermutlich vor allem die Variable `cnt` interessant.\n",
    "\n",
    "> cnt: count of total rental bikes including both casual and registered\n",
    "\n",
    "Damit könnte eine Organisation beispielsweise eine Vorhersage darüber treffen, wieviele Fahrräder zu einem bestimmten Zeitpunkt gerade ausgeliehen sind. So könnte man beispielsweise besser planen zu welchen Zeiten besonders viele Fahrräder zur Verfügung stehen müssen. `cnt` ist in diesem Beispiel also unsere **Zielvariable**! Da `cnt` lediglich die Summe von `casual` (count of casual users) und `registered` (count of registered users) ist, müssen wir die Variablen `casual` und `registered` ebenfalls vorher rausnehmen, weil wir eine Vorhersage ja lediglich durch die Umgebungsvariablen wie bspw. die Wetterbedingungen treffen wollen.\n",
    "\n",
    "`cnt` = `casual` + `registered`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a079a9-3d34-4592-b8b1-23b8b67d9585",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_split <- data %>%\n",
    "    select(-instant, -dteday) %>%\n",
    "    select(-casual, -registered) %>%\n",
    "    initial_split(prop = 0.75)\n",
    "\n",
    "train_data <- training(data_split)\n",
    "test_data <- testing(data_split)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20a5666b-1ebc-42b2-80b7-3d75e90b00ce",
   "metadata": {},
   "source": [
    "## Modell trainieren\n",
    "\n",
    "### Pre-Processing mit `recipe`\n",
    "\n",
    "<img src=\"https://recipes.tidymodels.org/logo.png\" alt=\"recipe\" width=\"100\" align=\"right\" /> Für das Modellieren gehen wir recht analog vor wie bei der Klassifikation mit Decision Trees. Allerdings wollen wir diese Woche das ganze noch etwas formalisieren. Im `tidymodels` Universum gibt es das Paket `recipe`. Mit `recipe` können wir analog zu `dplyr` Pipe-Sequenzen zum Pre-Processing des Modells einbauen. Das wird uns vor allem später beim Tuning des Modells helfen. Aber auch schon an dieser Stelle kann `recipe` nützlich sein, weil es den gesamten Prozess etwas formalisiert.\n",
    "\n",
    "`recipe` benutzt mindestens zwei Funktionen. Innerhalb von `recipe()` geben wir wie gewohnt unsere Zielvariable mithilfe der Tilde `~` an. Das Rezept wird dann mit der Funktion `prep()` quasi \"vorbereitet\" bzw. geupdatet. Zwischen `recipe()` und `prep()` können wir alle Schritte des Pre-Processings schreiben, die unser Datensatz braucht. Dazu gleich mehr.\n",
    "\n",
    "Wir können für unser Beispiel direkt ein einfaches Rezept erstellen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "477acbbf-a6fb-440a-80fc-27b366180863",
   "metadata": {},
   "outputs": [],
   "source": [
    "bikes_recipe <- train_data %>%\n",
    "    recipe(cnt ~ .) %>%\n",
    "    prep() %>%\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60073d77-4428-41fa-8b9b-fa5a1b045e85",
   "metadata": {},
   "source": [
    "Auch hier benutzen wir wieder die Tilde, um die Beziehung unserer Zielvariablen zu definieren. `cnt ~ .` bedeutet hier einfach, dass wir `cnt` als Zielvariable (outcome) und alle anderen Variablen als Prädiktoren (predictor) definieren! \n",
    "\n",
    "Wir setzen an dieser Stelle tatsächlich noch gar nicht fest, was wir eigentlich für ein Modell verwenden wollen (also ob z.B. lineare Regression oder ein Decision Tree). \n",
    "\n",
    "Wenn wir unser `recipe` ausgeben, erhalten wir direkt einige Informationen über unseren Datensatz, nämlich die Anzahl der Ziel-/Prädiktorvariablen sowie die Größe des Trainingsdatensatzes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbe8d702-7579-42a2-8c05-1625650eb67f",
   "metadata": {},
   "source": [
    "Wir erinnern uns: Regressionsmodelle können lediglich mit numerischen Variablen arbeiten. Allerdings haben wir in unserem Datensatz auch einige Variablen von anderen Datentypen, nämlich `logical` (binäre Variablen, also `TRUE` und `FALSE`) und `factor` (Faktoren).\n",
    "\n",
    "Da ein Regressionsmodell mit diesen anderen Datentypen nicht arbeiten kann, müssen wir diese Datentypen enkodieren, also in ein numerisches Format umwandeln. Mit `recipe` geht das ganz komfortabel, indem wir einfach einen Pre-Processing Schritt zwischen `recipe()` und `prep()` einfügen. Als erstes benutzen wir `step_mutate()` um alle Variablen vom Typ `logical` in Faktoren umzuwandeln. Das funktioniert analog zum `mutate()` in `dplyr`. \n",
    "\n",
    "Anschließend benutzen wir `step_dummy(all_nomimal_predictors)`. `step_dummy()` enkodiert alle Variablen, die übergeben werden. Das sind in diesem Fall alle kategorialen Variablen, die wir mit `all_nominal_predictors()` ausgewählt haben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0cd6b92-79b0-4adc-a722-f7e450bcc0c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "bikes_recipe <- train_data %>%\n",
    "    recipe(cnt ~ .) %>%\n",
    "    step_mutate(across(where(is.logical), as.factor)) %>% # Mutate logical variables to factors\n",
    "    step_dummy(all_nominal_predictors()) %>%              # Encode categorical variables if needed\n",
    "    prep() %>%\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cbd5381-38c7-48fa-ad2a-46bda86270f3",
   "metadata": {},
   "source": [
    "Wie sieht unser Datensatz jetzt aus? Um den durch pre-processed Datensatz auszugeben, können wir die Funktion `juice()` benutzen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea747478-e3d9-49d6-acaa-f54df9a07b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "bikes_recipe %>% \n",
    "    juice() %>% \n",
    "    head(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "318c2558-e2a4-47fa-b03b-10d6343587a3",
   "metadata": {},
   "source": [
    "Wie wir sehen, hat `recipe` alle Variablen im Datensatz in numerische Variablen umgewandelt."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "846c32ec-524e-4ea6-a4f5-9d66c6b53430",
   "metadata": {},
   "source": [
    "Ein weiterer Schritt im Pre-Processing ist das Filtern von `NAs`. Das funktioniert in `recipe` mit der Funktion `step_impute_mean(all_numeric_predictors())`. Diese Funktion ersetzt jedes `NA` im Datensatz mit dem `mean` der dazugehörigen Variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ff8b61-fe5e-4c79-aaa7-3d6ca1a8d714",
   "metadata": {},
   "outputs": [],
   "source": [
    "bikes_recipe <- train_data %>%\n",
    "    recipe(cnt ~ .) %>%\n",
    "    step_mutate(across(where(is.logical), as.factor)) %>% # Mutate logical variables to factors\n",
    "    step_dummy(all_nominal_predictors()) %>%              # Encode categorical variables if needed\n",
    "    step_impute_mean(all_numeric_predictors()) %>%        # Impute missing values for numeric predictors\n",
    "    prep() %>%\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01ed4b5e-31be-41bb-b39a-05bc7b27f90b",
   "metadata": {},
   "source": [
    "In der Regel gibt es bei einem Datensatz mit so vielen Variablen auch Korrelationen unter den Prädiktoren. Das liegt gerade bei Wetterdaten auf der Hand - die `season` (Jahreszeit) hat z.B. vermutlich einen Einfluss auf die Temperatur `temp`. Manche Modelle werden ungenauer durch stark korrelierende Prädiktoren. Decision Trees sind i.d.R. ziemlich robust gegenüber korrelierenden Prädiktoren, wir können diese der Vollständigkeit halber aber trotzdem ausschließen.\n",
    "\n",
    "In `recipe` macht das die Funktion `step_corr(all_predictors())` automatisch für uns. Diese findet heraus, welche Prädiktoren stark miteinander korrelieren, und schließt diese aus dem Datensatz aus.\n",
    "\n",
    "Analog können wir auch Prädiktoren ausschließen, die keine Varianz in den Daten haben. Prädiktoren ohne Varianz würden unser Modell nicht verbessern, aber unnötige Rechenleistung in Anspruch nehmen. In `recipe` machen wir das mit der Funktion `step_zv(all_predictors())`.\n",
    "\n",
    "Unser fertiges Rezept sieht jetzt folgendermaßen aus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0184156-3226-482c-a44d-ca5c3db496e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "bikes_recipe <- train_data %>%\n",
    "    recipe(cnt ~ .) %>%\n",
    "    step_mutate(across(where(is.logical), as.factor)) %>% # Mutate logical variables to factors\n",
    "    step_dummy(all_nominal_predictors()) %>%              # Encode categorical variables if needed\n",
    "    step_impute_mean(all_numeric_predictors()) %>%        # Impute missing values for numeric predictors\n",
    "    step_corr(all_predictors()) %>%                       # Remove correlating predictors\n",
    "    step_zv(all_predictors()) %>%                         # Remove zero-variance predictors\n",
    "    prep() %>%\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b04112-f3b1-4558-9624-0261da6b4184",
   "metadata": {},
   "source": [
    "Der Output ist jetzt etwas länger geworden. Hinzugekommen sind die Schritte im Pre-Processing, die wir eingefügt haben. Diese werden unter Operations angezeigt.\n",
    "\n",
    "* Wir haben alle Prädiktoren vom Datentyp `logical` in Faktoren umgewandelt\n",
    "* Alle Faktoren wurden in numerische Variablen enkodiert\n",
    "* Fehlende Werte (`NA`) haben wir ersetzt\n",
    "* Korrelierende Variablen werden gefiltert\n",
    "* ... und alle Prädiktoren ohne Varianz wurden herausgefiltert (das war bei uns tatsächlich nicht der Fall).\n",
    "\n",
    "Unser Rezept ist relativ lang geworden, und die vielen verschiedenen Schritte des Pre-Processings können erstmal etwas unübersichtlich wirken. Tatsächlich kennt `recipe` noch eine [Vielzahl](https://recipes.tidymodels.org/reference/index.html) an weiteren Schritten. Falls ihr mal ein komplexeres Modell bauen werdet, lohnt es sich, mit dem Pre-Processing auseinander zu setzen. \n",
    "\n",
    "> Zwei typische weitere Operationen bei der Verwendung von kontinuierlichen numerischen Daten sind *Centering* und *Normalization*, in Kombination auch *Standardisation* genannt. Dabei werden die Datenpunkte zentriert, sodass der Mittelwert jedes Prädiktors 0 ist, und anschließend normalisiert (genormt), sodass jeder Prädiktor eine Standardabweichung von 1 hat. Die Prädiktor-Variablen werden so auf einen ähnlichen Wertebereich gebracht. Die Standardisierung von numerischen Daten verbessert viele Modelle. Decision Trees sind aufgrund ihres Splitting-Algorithmus allerdings unabhängig von Standardisierung, sodass wir diese an dieser Stelle weglassen können.\n",
    "\n",
    "Jetzt sind wir fertig mit dem Pre-Processing. Das Tolle an `recipe` ist, dass wir dafür den ursprünglichen Datensatz `data` gar nicht verändern mussten! `recipe` merkt sich einfach, welche Operationen wir auf den Datensatz anwenden wollen und führt das ganze dann nur aus, wenn wir es zum Trainieren oder Testen benötigen. Außerdem könnten wir mit diesem Datensatz jetzt auch verschiedene Modelle trainieren! Wir haben also eine Art Kochrezept für die richtige Vorbereitung der Daten geschrieben."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22abef7d-e085-4eb5-80bf-3736c534c988",
   "metadata": {},
   "source": [
    "### Modellauswahl\n",
    "\n",
    "Im nächsten Schritt legen wir das Modell fest. Im Prinzip funktioniert das recht analog zu letzter Woche. Wir wollen wieder ein einfach `decision_tree()`-Modell trainieren, wieder mit der `rpart`-Engine. Diesmal wählen wir aber ein Regressionsmodell aus. Das könnt ihr einstellen, indem ihr `set_mode(\"regression\") hinzufügt. \n",
    "\n",
    "6. Könnt ihr euch noch erinnern, wie ihr einen Decision Tree initialisiert? Speichert diesen in der Variable `bikes_model`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ce1f56-1929-4656-acb4-72945a23a0e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fd982bf7-4f19-457e-87fc-0758e1fb7aed",
   "metadata": {},
   "source": [
    "### `workflows`\n",
    "\n",
    "<img src=\"https://workflows.tidymodels.org/logo.png\" alt=\"recipe\" width=\"100\" align=\"right\" /> Wie bringen wir jetzt Pre-Processing und das Modell zusammen? Dafür gibt es in `tidymodels` das Paket `workflows`. `workflows` wird vor allem später interessant, wenn wir unser Modell auch finetunen wollen. So weit sind wir an dieser Stelle zwar noch nicht, trotzdem können wir hier bereits `workflows` benutzen. Im Prinzip macht `workflows` nichts anderes, als Pre-Processing und Modell hintereinanderzuschalten. Im Code sieht das dann auch recht einfach aus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c021a1-f653-46f8-acee-c702b872e38d",
   "metadata": {},
   "outputs": [],
   "source": [
    "bikes_workflow <- workflow() %>%\n",
    "    add_model(bikes_model) %>%\n",
    "    add_recipe(bikes_recipe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bddcb08-739b-4a79-b0a3-69541380ab5d",
   "metadata": {},
   "source": [
    "Wie unser Rezept können wir auch unseren Workflow ausgeben lassen. Dort kriegen wir dann übersichtlich alle wichtigen Informationen über Pre-Processing und Modell angezeigt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7262edc-428d-42a8-9c11-2437a6eb4483",
   "metadata": {},
   "outputs": [],
   "source": [
    "bikes_workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "154a28cd-feba-4831-a360-2f2d46b0908b",
   "metadata": {},
   "source": [
    "### Training\n",
    "\n",
    "Jetzt kann das eigentliche Training des Modells stattfinden. Dafür benutzen wir wieder `fit()`. Da wir Pre-Processing und Modell in unserem Workflow `bikes_workflow` gespeichert haben, ist der Code übersichtlich. Wir müssen lediglich die Trainingsdaten angeben:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e35ef7cf-515f-4911-9796-000fb995127e",
   "metadata": {},
   "outputs": [],
   "source": [
    "bikes_fit <- bikes_workflow %>% \n",
    "    fit(data = train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c5a727a-70dd-42d8-9734-d5d26d9d1fca",
   "metadata": {},
   "source": [
    "Um die Regeln des trainierten Decision Trees anzuzeigen, können wir `extract_fit_parsnip()` benutzen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e9dca6-32ef-40f4-88ad-f29845d07529",
   "metadata": {},
   "outputs": [],
   "source": [
    "bikes_fit %>% \n",
    "    extract_fit_parsnip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d060543-3da4-496e-b2d1-c1795d65e836",
   "metadata": {},
   "source": [
    "Fertig, das Modell ist trainiert!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d5c6477-8ad2-4d9d-9541-31262d4b2963",
   "metadata": {},
   "source": [
    "## Modell evaluieren\n",
    "\n",
    "<img src=\"https://parsnip.tidymodels.org/logo.png\" alt=\"parsnip\" width=\"100\" align=\"right\"/><img src=\"https://yardstick.tidymodels.org/logo.png\" alt=\"yardstick\" width=\"100\" align=\"right\"/> Für die Evaluation benutzen wir wieder Funktionen von `parsnip` und `yardstick`.\n",
    "\n",
    "Mit `augment(test_data)` wenden wir das Modell auf die Testdaten an und übergeben die vorhergesagten Ergebnisse dann anschließend der Funktion `metrics()`.\n",
    "\n",
    "Da wir diesmal eine Regressionsanalyse vorgenommen haben statt einem Klassifizierungsproblem, brauchen wir andere Metriken! `yardstick` ist schlau genug, um zu das Regressionsmodell zu erkennen, und wählt automatisch die entsprechenden Metriken aus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a8e716-909b-49d7-8d5a-617a9501322b",
   "metadata": {},
   "outputs": [],
   "source": [
    "bikes_fit %>% \n",
    "    augment(test_data) %>% \n",
    "    metrics(truth = cnt, estimate = .pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cb24a08-52ba-42a1-ae97-6ed1c2954426",
   "metadata": {},
   "source": [
    "7. Recherchiert, was die Metriken `rmse`, `rsq` und `mae` bedeuten."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b58d8aff-1327-4586-8210-352ec3fc8ede",
   "metadata": {},
   "source": [
    "Unser Modell erreicht ein R-squared von etwa 0.7. Das bedeutet, dass etwa 70 Prozent der Varianz der Zielvariable von den Prädiktoren erklärt werden kann. Ein ganz guter Ausgangswert für eine Vorhersage, mit einem gleichzeitig großen Potential für Verbesserung!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9484108-d5b8-47c2-b149-4bd0164e754f",
   "metadata": {},
   "source": [
    "### Variable importance\n",
    "\n",
    "Wir können natürlich auch wieder Variable Importance berechnen, um den Einfluss der einzelnen Prädiktoren einzuschätzen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b654de30-9ff4-4bad-be4f-f9cfa441bdbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "bikes_fit %>% \n",
    "    extract_fit_parsnip() %>% # extract the model\n",
    "    vi(scale = TRUE) %>%      # scale the most important variable to 100\n",
    "    head(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "684bcac8-bfb2-43dc-9a2f-9d5b527cd821",
   "metadata": {},
   "source": [
    "Den größten Einfluss hat die Variable `hr`, welche für die Tagesuhrzeit steht. Auch ziemlich entscheidend ist die gefühlte Temperatur `atemp`. Das lässt sich beides relativ klar begründen – nachts fahren vermutlich weniger Menschen mit Bike Sharing als tagsüber, ebenso fahren mehr Menschen wenn es warm genug ist, und weniger Menschen, wenn es draußen kalt ist. \n",
    "\n",
    "In einem richtigen Anwendungsfall ist es sehr wichtig zu verstehen, welche Prädiktoren welchen Einfluss auf die Zielvariable haben.\n",
    "\n",
    "Um die Variable Importance besser nachzuvollziehen, kann man auch an dieser Stelle nochmal versuchen, die einzelnen Variablen zu plotten. Z.B. können wir den durchschnittlichen Count an ausgeliehen Fahrrädern `cnt` pro Stunde darstellen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cbe1149-6238-4436-901f-bc1daa40dcf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data %>%\n",
    "    select(hr, cnt) %>%\n",
    "    group_by(hr) %>%\n",
    "    summarise(cnt = mean(cnt)) %>%\n",
    "ggplot(aes(x = hr, y = cnt)) +\n",
    "    geom_line() +\n",
    "    theme_minimal(base_size = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db9d5d4c-d7e8-4f32-b532-ffe493d9469a",
   "metadata": {},
   "source": [
    "Hier sehen wir bereits, dass die Tageszeit einen starken Einfluss auf `cnt` hat. Nachts gibt es einen Zeitraum, an dem fast gar keine Fahrräder ausgeliehen sind, außerdem gibt es zwei Peaks zu den Stoßzeiten um 8 und 17 Uhr.\n",
    "\n",
    "Ebenso können wir die Abhängigkeit von `cnt` und `atemp` darstellen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c80cc17c-0109-423e-8730-e68b0c345271",
   "metadata": {},
   "outputs": [],
   "source": [
    "data %>%\n",
    "    select(atemp, cnt) %>%\n",
    "    group_by(atemp) %>%\n",
    "    summarise(cnt = mean(cnt)) %>%\n",
    "    ggplot(aes(x = atemp, y = cnt)) +\n",
    "    geom_line() +\n",
    "    theme_minimal(base_size = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd4c013e-dfef-4bcc-8b56-aa9630a3cfed",
   "metadata": {},
   "source": [
    "## Vorhersagen treffen\n",
    "\n",
    "Wie bei den Pilzen müssen wir jetzt einen neuen `tibble` erstellen, den wir anschließend mithilfe von `predict()` vorhersagen können. Dabei ist zu beachten, dass einige der Prädiktorvariablen vorher bereits im Datensatz normalisiert worden waren! Das ist im Readme hinterlegt und im folgenden Code auch nochmal kommentiert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "601d50ce-3951-475e-b445-465b389eb510",
   "metadata": {},
   "outputs": [],
   "source": [
    "vorhersage <- tibble(\n",
    "    # Possible occurences for season: spring, summer, fall, winter\n",
    "    season = \"winter\", \n",
    "\n",
    "    # Possible occurences for yr: 2011, 2012\n",
    "    yr = 2011,\n",
    "    \n",
    "    mnth = 2, \n",
    "    hr = 11, \n",
    "\n",
    "    # TRUE or FALSE\n",
    "    holiday = FALSE,\n",
    "\n",
    "    weekday = 5,\n",
    "    \n",
    "    # TRUE or FALSE\n",
    "    workingday = TRUE,\n",
    "    \n",
    "    # Possible occurences for weathersit\n",
    "        # Clear, Few clouds, Partly cloudy, Partly cloudy\n",
    "        # Mist + Cloudy, Mist + Broken clouds, Mist + Few clouds, Mist\n",
    "        # Light Snow, Light Rain + Thunderstorm + Scattered clouds, Light Rain + Scattered clouds\n",
    "        # Heavy Rain + Ice Pallets + Thunderstorm + Mist, Snow + Fog\n",
    "    weathersit = \"Mist + Cloudy, Mist + Broken clouds, Mist + Few clouds, Mist\", \n",
    "    \n",
    "    # Celsius, normalised temperature through division by 41\n",
    "    temp = 30 / 41, \n",
    "    \n",
    "    # Celsius, normalised feeling temperature through division by 50\n",
    "    atemp = 25 / 50, \n",
    "    \n",
    "    # percentage, normalised through division by 100\n",
    "    hum = 20 / 100, \n",
    "    \n",
    "    # normalised through division 67\n",
    "    windspeed = 35 / 67, \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10364dee-6139-49b5-ba29-dbec6c7173ed",
   "metadata": {},
   "source": [
    "Wir können mit unserem trainierten Workflow `bikes_fit` und `predict()` eine Vorhersage treffen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c05291a-6f1a-4fd6-94de-e66e8c5de317",
   "metadata": {},
   "outputs": [],
   "source": [
    "bikes_fit %>% predict(vorhersage)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dbd2be4-aa88-43e8-95eb-b460fb846818",
   "metadata": {},
   "source": [
    "Voilà – das ist die Anzahl der Fahrräder, die laut unserem Modell bei den von uns definierten Umgebungsvariablen ausgeliehen werden. Wir können jetzt also Vorhersagen darüber treffen."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e9dad5-6871-4d3d-a5fc-a051159a0d37",
   "metadata": {},
   "source": [
    "## Modell verbessern\n",
    "\n",
    "Durch die Schritte im Pre-Processing haben wir unser Modell vermutlich schon minimal verbessert im Vergleich zu einem Modell ohne Pre-Processing. Hilfreich ist meistens eine größere Datenbasis. Tatsächlich sind die Decision Trees aber relativ beschränkt in ihrer Funktionsweise, sodass es sich vor allem lohnt, ein komplexeres Modell zu verwenden.\n",
    "\n",
    "Ein Beispiel dafür sind sogenannte **Random Forests**, die in `tidymodels` in der Funktion [`rand_forest()`](https://parsnip.tidymodels.org/reference/rand_forest.html) abgebildet werden. Dieses Beispiel wird im nächsten Notebook behandelt."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.4.2"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
